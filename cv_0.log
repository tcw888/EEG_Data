Network (layers=19)
inputs (x_train_inputs:0): (100, 3000, 1, 1)
targets (x_train_targets:0): (100,)
l1_conv (deepfeaturenet/l1_conv/relu:0): (100, 500, 1, 64)
l2_pool (deepfeaturenet/l2_pool:0): (100, 63, 1, 64)
l3_dropout (deepfeaturenet/l3_dropout/mul:0): (100, 63, 1, 64)
l4_conv (deepfeaturenet/l4_conv/relu:0): (100, 63, 1, 128)
l5_conv (deepfeaturenet/l5_conv/relu:0): (100, 63, 1, 128)
l6_conv (deepfeaturenet/l6_conv/relu:0): (100, 63, 1, 128)
l7_pool (deepfeaturenet/l7_pool:0): (100, 16, 1, 128)
l8_flat (deepfeaturenet/l8_flat:0): (100, 2048)
l9_conv (deepfeaturenet/l9_conv/relu:0): (100, 60, 1, 64)
l10_pool (deepfeaturenet/l10_pool:0): (100, 15, 1, 64)
l11_dropout (deepfeaturenet/l11_dropout/mul:0): (100, 15, 1, 64)
l12_conv (deepfeaturenet/l12_conv/relu:0): (100, 15, 1, 128)
l13_conv (deepfeaturenet/l13_conv/relu:0): (100, 15, 1, 128)
l14_conv (deepfeaturenet/l14_conv/relu:0): (100, 15, 1, 128)
l15_pool (deepfeaturenet/l15_pool:0): (100, 8, 1, 128)
l16_flat (deepfeaturenet/l16_flat:0): (100, 1024)
l17_concat (deepfeaturenet/l17_concat:0): (100, 3072)
l18_dropout (deepfeaturenet/l18_dropout/mul:0): (100, 3072)
l19_softmax_linear (deepfeaturenet/l19_softmax_linear/Add:0): (100, 5)
 
[2018-01-25 22:19:03.435539] Start pre-training ...


========== [Fold-0] ==========

Load training set:
Loading data/eeg_fpz_cz/SC4011E0.npz ...
Loading data/eeg_fpz_cz/SC4012E0.npz ...
Loading data/eeg_fpz_cz/SC4021E0.npz ...
Loading data/eeg_fpz_cz/SC4022E0.npz ...
Loading data/eeg_fpz_cz/SC4031E0.npz ...
Loading data/eeg_fpz_cz/SC4032E0.npz ...
Loading data/eeg_fpz_cz/SC4041E0.npz ...
Loading data/eeg_fpz_cz/SC4042E0.npz ...
Loading data/eeg_fpz_cz/SC4051E0.npz ...
Loading data/eeg_fpz_cz/SC4052E0.npz ...
Loading data/eeg_fpz_cz/SC4061E0.npz ...
Loading data/eeg_fpz_cz/SC4062E0.npz ...
Loading data/eeg_fpz_cz/SC4071E0.npz ...
Loading data/eeg_fpz_cz/SC4072E0.npz ...
Loading data/eeg_fpz_cz/SC4081E0.npz ...
Loading data/eeg_fpz_cz/SC4082E0.npz ...
Loading data/eeg_fpz_cz/SC4091E0.npz ...
Loading data/eeg_fpz_cz/SC4092E0.npz ...
Loading data/eeg_fpz_cz/SC4101E0.npz ...
Loading data/eeg_fpz_cz/SC4102E0.npz ...
Loading data/eeg_fpz_cz/SC4111E0.npz ...
Loading data/eeg_fpz_cz/SC4112E0.npz ...
Loading data/eeg_fpz_cz/SC4121E0.npz ...
Loading data/eeg_fpz_cz/SC4122E0.npz ...
Loading data/eeg_fpz_cz/SC4131E0.npz ...
Loading data/eeg_fpz_cz/SC4141E0.npz ...
Loading data/eeg_fpz_cz/SC4142E0.npz ...
Loading data/eeg_fpz_cz/SC4151E0.npz ...
Loading data/eeg_fpz_cz/SC4152E0.npz ...
Loading data/eeg_fpz_cz/SC4161E0.npz ...
Loading data/eeg_fpz_cz/SC4162E0.npz ...
Loading data/eeg_fpz_cz/SC4171E0.npz ...
Loading data/eeg_fpz_cz/SC4172E0.npz ...
Loading data/eeg_fpz_cz/SC4181E0.npz ...
Loading data/eeg_fpz_cz/SC4182E0.npz ...
Loading data/eeg_fpz_cz/SC4191E0.npz ...
Loading data/eeg_fpz_cz/SC4192E0.npz ...
 
Load validation set:
Loading data/eeg_fpz_cz/SC4001E0.npz ...
Loading data/eeg_fpz_cz/SC4002E0.npz ...
 
Training set: (40340, 3000, 1, 1), (40340,)
W: 7914
N1: 2687
N2: 17176
N3: 5186
REM: 7377
 
Validation set: (1968, 3000, 1, 1), (1968,)
W: 371
N1: 117
N2: 623
N3: 517
REM: 340
 
Oversampled training set: (85880, 3000, 1, 1), (85880,)
W: 17176
N1: 17176
N2: 17176
N3: 17176
REM: 17176
 
epoch 1: train (19.37 sec): n=85800, loss=1.195 (0.049), acc=0.535, f1=0.536 | valid (0.21 sec): n=1900, loss=2.672 (0.049), acc=0.371, f1=0.249
epoch 2: train (17.22 sec): n=85800, loss=0.847 (0.047), acc=0.670, f1=0.670 | valid (0.22 sec): n=1900, loss=1.327 (0.047), acc=0.606, f1=0.479
epoch 3: train (17.25 sec): n=85800, loss=0.728 (0.045), acc=0.723, f1=0.723 | valid (0.22 sec): n=1900, loss=1.025 (0.045), acc=0.698, f1=0.552
epoch 4: train (17.28 sec): n=85800, loss=0.670 (0.043), acc=0.747, f1=0.747 | valid (0.21 sec): n=1900, loss=0.876 (0.043), acc=0.754, f1=0.610
epoch 5: train (17.24 sec): n=85800, loss=0.633 (0.041), acc=0.762, f1=0.762 | valid (0.22 sec): n=1900, loss=0.706 (0.041), acc=0.802, f1=0.663
epoch 6: train (17.26 sec): n=85800, loss=0.607 (0.040), acc=0.773, f1=0.773 | valid (0.22 sec): n=1900, loss=0.739 (0.040), acc=0.777, f1=0.644
epoch 7: train (17.24 sec): n=85800, loss=0.585 (0.038), acc=0.782, f1=0.782 | valid (0.21 sec): n=1900, loss=0.822 (0.038), acc=0.758, f1=0.620
epoch 8: train (17.25 sec): n=85800, loss=0.567 (0.036), acc=0.790, f1=0.790 | valid (0.21 sec): n=1900, loss=0.666 (0.036), acc=0.778, f1=0.675
epoch 9: train (17.25 sec): n=85800, loss=0.552 (0.035), acc=0.795, f1=0.796 | valid (0.22 sec): n=1900, loss=0.678 (0.035), acc=0.778, f1=0.665
 
[2018-01-25 22:22:11.203221] epoch 10:
train (17.287 sec): n=85800, loss=0.536 (0.033), acc=0.802, f1=0.802
[[14680  1993   124    67   299]
 [ 1288 11353  1409    63  3042]
 [  165  1204 13478  1130  1185]
 [   64    27   887 16145    34]
 [  325  2761   896    27 13154]]
valid (0.215 sec): n=1900, loss=0.572 (0.033), acc=0.800, f1=0.695
[[180  80   0   1  50]
 [  0  23   9   1  84]
 [  0   4 492  41  78]
 [  0   0  13 502   2]
 [  1  13   3   0 323]]
 
epoch 11: train (17.26 sec): n=85800, loss=0.524 (0.032), acc=0.807, f1=0.807 | valid (0.21 sec): n=1900, loss=0.492 (0.032), acc=0.828, f1=0.734
epoch 12: train (17.24 sec): n=85800, loss=0.512 (0.031), acc=0.812, f1=0.812 | valid (0.21 sec): n=1900, loss=0.473 (0.031), acc=0.824, f1=0.741
epoch 13: train (17.27 sec): n=85800, loss=0.501 (0.029), acc=0.816, f1=0.817 | valid (0.22 sec): n=1900, loss=0.523 (0.029), acc=0.812, f1=0.728
epoch 14: train (17.27 sec): n=85800, loss=0.490 (0.028), acc=0.821, f1=0.822 | valid (0.21 sec): n=1900, loss=0.483 (0.028), acc=0.822, f1=0.737
epoch 15: train (17.24 sec): n=85800, loss=0.479 (0.027), acc=0.823, f1=0.824 | valid (0.21 sec): n=1900, loss=0.454 (0.027), acc=0.833, f1=0.756
epoch 16: train (17.24 sec): n=85800, loss=0.472 (0.027), acc=0.827, f1=0.828 | valid (0.21 sec): n=1900, loss=0.469 (0.027), acc=0.827, f1=0.747
epoch 17: train (17.26 sec): n=85800, loss=0.462 (0.026), acc=0.832, f1=0.833 | valid (0.21 sec): n=1900, loss=0.464 (0.026), acc=0.825, f1=0.743
epoch 18: train (17.24 sec): n=85800, loss=0.458 (0.025), acc=0.832, f1=0.833 | valid (0.21 sec): n=1900, loss=0.511 (0.025), acc=0.807, f1=0.727
epoch 19: train (17.25 sec): n=85800, loss=0.451 (0.024), acc=0.834, f1=0.835 | valid (0.22 sec): n=1900, loss=0.433 (0.024), acc=0.832, f1=0.761
 
[2018-01-25 22:25:12.410905] epoch 20:
train (17.230 sec): n=85800, loss=0.439 (0.024), acc=0.840, f1=0.840
[[15189  1516   121    54   287]
 [  944 12972  1087    30  2116]
 [  152  1173 13738  1049  1053]
 [   53    27   788 16268    23]
 [  256  2247   742    12 13903]]
valid (0.220 sec): n=1900, loss=0.490 (0.024), acc=0.817, f1=0.741
[[202  90   1   1  17]
 [  1  51   6   2  57]
 [  0  26 503  48  38]
 [  0   0  11 506   0]
 [  2  43   4   0 291]]
 
epoch 21: train (17.26 sec): n=85800, loss=0.435 (0.023), acc=0.842, f1=0.842 | valid (0.22 sec): n=1900, loss=0.503 (0.023), acc=0.816, f1=0.734
epoch 22: train (17.24 sec): n=85800, loss=0.425 (0.022), acc=0.846, f1=0.847 | valid (0.21 sec): n=1900, loss=0.477 (0.022), acc=0.817, f1=0.736
epoch 23: train (17.22 sec): n=85800, loss=0.418 (0.022), acc=0.848, f1=0.848 | valid (0.21 sec): n=1900, loss=0.420 (0.022), acc=0.848, f1=0.771
epoch 24: train (17.23 sec): n=85800, loss=0.413 (0.021), acc=0.849, f1=0.850 | valid (0.22 sec): n=1900, loss=0.451 (0.021), acc=0.828, f1=0.752
epoch 25: train (17.26 sec): n=85800, loss=0.403 (0.021), acc=0.853, f1=0.854 | valid (0.22 sec): n=1900, loss=0.486 (0.021), acc=0.826, f1=0.738
epoch 26: train (17.20 sec): n=85800, loss=0.400 (0.020), acc=0.857, f1=0.857 | valid (0.22 sec): n=1900, loss=0.488 (0.020), acc=0.825, f1=0.754
epoch 27: train (17.24 sec): n=85800, loss=0.392 (0.020), acc=0.859, f1=0.860 | valid (0.21 sec): n=1900, loss=0.422 (0.020), acc=0.854, f1=0.778
epoch 28: train (17.21 sec): n=85800, loss=0.386 (0.019), acc=0.861, f1=0.861 | valid (0.21 sec): n=1900, loss=0.491 (0.019), acc=0.825, f1=0.757
epoch 29: train (17.29 sec): n=85800, loss=0.380 (0.019), acc=0.863, f1=0.864 | valid (0.22 sec): n=1900, loss=0.438 (0.019), acc=0.834, f1=0.755
 
[2018-01-25 22:28:13.541086] epoch 30:
train (17.254 sec): n=85800, loss=0.375 (0.018), acc=0.866, f1=0.866
[[15488  1178   112    46   339]
 [  715 14043   830    16  1555]
 [  162  1086 13962   959   989]
 [   38    15   712 16377    14]
 [  269  1726   729    13 14427]]
valid (0.211 sec): n=1900, loss=0.449 (0.018), acc=0.836, f1=0.758
[[228  71   0   1  11]
 [  4  49  10   1  53]
 [  3  19 523  36  34]
 [  1   0  12 504   0]
 [  3  44   9   0 284]]
 
epoch 31: train (17.22 sec): n=85800, loss=0.366 (0.018), acc=0.869, f1=0.869 | valid (0.21 sec): n=1900, loss=0.449 (0.018), acc=0.833, f1=0.754
epoch 32: train (17.25 sec): n=85800, loss=0.363 (0.018), acc=0.871, f1=0.871 | valid (0.21 sec): n=1900, loss=0.478 (0.018), acc=0.823, f1=0.753
epoch 33: train (17.24 sec): n=85800, loss=0.354 (0.017), acc=0.874, f1=0.874 | valid (0.22 sec): n=1900, loss=0.416 (0.017), acc=0.851, f1=0.775
epoch 34: train (17.23 sec): n=85800, loss=0.348 (0.017), acc=0.875, f1=0.875 | valid (0.22 sec): n=1900, loss=0.451 (0.017), acc=0.833, f1=0.758
epoch 35: train (17.22 sec): n=85800, loss=0.347 (0.017), acc=0.877, f1=0.877 | valid (0.22 sec): n=1900, loss=0.451 (0.017), acc=0.839, f1=0.765
epoch 36: train (17.25 sec): n=85800, loss=0.343 (0.016), acc=0.878, f1=0.878 | valid (0.21 sec): n=1900, loss=0.494 (0.016), acc=0.830, f1=0.749
epoch 37: train (17.25 sec): n=85800, loss=0.336 (0.016), acc=0.881, f1=0.881 | valid (0.22 sec): n=1900, loss=0.469 (0.016), acc=0.832, f1=0.762
epoch 38: train (17.24 sec): n=85800, loss=0.332 (0.016), acc=0.882, f1=0.883 | valid (0.22 sec): n=1900, loss=0.448 (0.016), acc=0.844, f1=0.772
epoch 39: train (17.23 sec): n=85800, loss=0.323 (0.016), acc=0.885, f1=0.885 | valid (0.22 sec): n=1900, loss=0.498 (0.016), acc=0.825, f1=0.755
 
[2018-01-25 22:31:14.594468] epoch 40:
train (17.199 sec): n=85800, loss=0.321 (0.015), acc=0.886, f1=0.886
[[15744   930   115    38   334]
 [  551 14798   645    11  1156]
 [  140   935 14189   918   979]
 [   39    15   677 16417    12]
 [  237  1370   705     9 14836]]
valid (0.217 sec): n=1900, loss=0.458 (0.015), acc=0.848, f1=0.758
[[250  40   2   1  18]
 [  6  32  13   3  63]
 [  1   8 529  30  47]
 [  0   0  19 497   1]
 [  4  25   8   0 303]]
 
epoch 41: train (17.24 sec): n=85800, loss=0.314 (0.015), acc=0.890, f1=0.890 | valid (0.22 sec): n=1900, loss=0.442 (0.015), acc=0.841, f1=0.762
epoch 42: train (17.21 sec): n=85800, loss=0.309 (0.015), acc=0.891, f1=0.891 | valid (0.22 sec): n=1900, loss=0.460 (0.015), acc=0.839, f1=0.766
epoch 43: train (17.21 sec): n=85800, loss=0.305 (0.015), acc=0.891, f1=0.891 | valid (0.22 sec): n=1900, loss=0.482 (0.015), acc=0.836, f1=0.760
epoch 44: train (17.23 sec): n=85800, loss=0.303 (0.014), acc=0.893, f1=0.893 | valid (0.21 sec): n=1900, loss=0.458 (0.014), acc=0.854, f1=0.759
epoch 45: train (17.21 sec): n=85800, loss=0.298 (0.014), acc=0.895, f1=0.895 | valid (0.22 sec): n=1900, loss=0.484 (0.014), acc=0.852, f1=0.756
epoch 46: train (17.21 sec): n=85800, loss=0.293 (0.014), acc=0.897, f1=0.897 | valid (0.22 sec): n=1900, loss=0.457 (0.014), acc=0.846, f1=0.773
epoch 47: train (17.23 sec): n=85800, loss=0.291 (0.014), acc=0.898, f1=0.898 | valid (0.22 sec): n=1900, loss=0.458 (0.014), acc=0.861, f1=0.766
epoch 48: train (17.28 sec): n=85800, loss=0.288 (0.014), acc=0.899, f1=0.899 | valid (0.22 sec): n=1900, loss=0.483 (0.014), acc=0.851, f1=0.754
epoch 49: train (17.25 sec): n=85800, loss=0.284 (0.013), acc=0.900, f1=0.900 | valid (0.22 sec): n=1900, loss=0.469 (0.013), acc=0.859, f1=0.763
 
[2018-01-25 22:34:15.813734] epoch 50:
train (17.270 sec): n=85800, loss=0.279 (0.013), acc=0.902, f1=0.902
[[16001   735   114    30   284]
 [  426 15305   533     9   884]
 [  155   784 14377   882   965]
 [   34     6   638 16472     8]
 [  207  1066   650     6 15229]]
valid (0.217 sec): n=1900, loss=0.459 (0.013), acc=0.853, f1=0.769
[[255  41   1   2  12]
 [  7  38  13   2  57]
 [  3  13 535  30  34]
 [  0   0  23 494   0]
 [  4  28   9   0 299]]
 
epoch 51: train (17.28 sec): n=85800, loss=0.274 (0.013), acc=0.904, f1=0.904 | valid (0.23 sec): n=1900, loss=0.480 (0.013), acc=0.843, f1=0.750
epoch 52: train (17.24 sec): n=85800, loss=0.272 (0.013), acc=0.904, f1=0.904 | valid (0.22 sec): n=1900, loss=0.471 (0.013), acc=0.849, f1=0.767
epoch 53: train (17.23 sec): n=85800, loss=0.267 (0.013), acc=0.908, f1=0.908 | valid (0.23 sec): n=1900, loss=0.486 (0.013), acc=0.848, f1=0.757
epoch 54: train (17.24 sec): n=85800, loss=0.264 (0.013), acc=0.908, f1=0.908 | valid (0.22 sec): n=1900, loss=0.475 (0.013), acc=0.852, f1=0.757
epoch 55: train (17.24 sec): n=85800, loss=0.260 (0.012), acc=0.909, f1=0.909 | valid (0.23 sec): n=1900, loss=0.455 (0.012), acc=0.862, f1=0.767
epoch 56: train (17.25 sec): n=85800, loss=0.255 (0.012), acc=0.911, f1=0.911 | valid (0.22 sec): n=1900, loss=0.487 (0.012), acc=0.853, f1=0.761
epoch 57: train (17.24 sec): n=85800, loss=0.255 (0.012), acc=0.912, f1=0.912 | valid (0.22 sec): n=1900, loss=0.493 (0.012), acc=0.852, f1=0.758
epoch 58: train (17.25 sec): n=85800, loss=0.250 (0.012), acc=0.912, f1=0.912 | valid (0.22 sec): n=1900, loss=0.453 (0.012), acc=0.858, f1=0.766
epoch 59: train (17.25 sec): n=85800, loss=0.250 (0.012), acc=0.913, f1=0.913 | valid (0.22 sec): n=1900, loss=0.506 (0.012), acc=0.854, f1=0.749
 
[2018-01-25 22:37:21.236283] epoch 60:
train (17.249 sec): n=85800, loss=0.246 (0.012), acc=0.915, f1=0.915
[[16156   593   120    28   257]
 [  365 15710   379     9   700]
 [  156   655 14619   795   930]
 [   27    12   569 16542    14]
 [  187   849   606     5 15517]]
valid (0.219 sec): n=1900, loss=0.484 (0.012), acc=0.859, f1=0.753
[[281  22   2   1   5]
 [ 13  19  15   0  70]
 [  4   5 540  24  42]
 [  2   0  33 481   1]
 [  6  15   8   0 311]]
 
epoch 61: train (17.23 sec): n=85800, loss=0.245 (0.012), acc=0.915, f1=0.915 | valid (0.22 sec): n=1900, loss=0.490 (0.012), acc=0.846, f1=0.768
epoch 62: train (17.25 sec): n=85800, loss=0.238 (0.012), acc=0.917, f1=0.917 | valid (0.22 sec): n=1900, loss=0.484 (0.012), acc=0.854, f1=0.760
epoch 63: train (17.21 sec): n=85800, loss=0.237 (0.011), acc=0.918, f1=0.917 | valid (0.22 sec): n=1900, loss=0.471 (0.011), acc=0.861, f1=0.770
epoch 64: train (17.27 sec): n=85800, loss=0.236 (0.011), acc=0.918, f1=0.918 | valid (0.23 sec): n=1900, loss=0.482 (0.011), acc=0.857, f1=0.775
epoch 65: train (17.27 sec): n=85800, loss=0.230 (0.011), acc=0.921, f1=0.921 | valid (0.23 sec): n=1900, loss=0.534 (0.011), acc=0.848, f1=0.753
epoch 66: train (17.24 sec): n=85800, loss=0.227 (0.011), acc=0.921, f1=0.921 | valid (0.22 sec): n=1900, loss=0.567 (0.011), acc=0.826, f1=0.733
epoch 67: train (17.24 sec): n=85800, loss=0.227 (0.011), acc=0.921, f1=0.921 | valid (0.23 sec): n=1900, loss=0.504 (0.011), acc=0.862, f1=0.764
epoch 68: train (17.23 sec): n=85800, loss=0.227 (0.011), acc=0.922, f1=0.921 | valid (0.23 sec): n=1900, loss=0.492 (0.011), acc=0.856, f1=0.758
epoch 69: train (17.24 sec): n=85800, loss=0.218 (0.011), acc=0.925, f1=0.924 | valid (0.24 sec): n=1900, loss=0.495 (0.011), acc=0.856, f1=0.766
 
[2018-01-25 22:40:22.682915] epoch 70:
train (17.237 sec): n=85800, loss=0.219 (0.011), acc=0.924, f1=0.924
[[16292   511   106    19   234]
 [  289 15903   320    10   634]
 [  120   579 14812   751   899]
 [   27     7   533 16587     8]
 [  178   751   570     6 15654]]
valid (0.222 sec): n=1900, loss=0.518 (0.011), acc=0.857, f1=0.756
[[271  29   1   1   9]
 [ 11  22  18   1  65]
 [  2   5 520  55  33]
 [  1   0  12 504   0]
 [  6  11  11   0 312]]
 
epoch 71: train (17.21 sec): n=85800, loss=0.216 (0.010), acc=0.925, f1=0.925 | valid (0.22 sec): n=1900, loss=0.518 (0.010), acc=0.852, f1=0.758
epoch 72: train (17.22 sec): n=85800, loss=0.213 (0.010), acc=0.926, f1=0.926 | valid (0.22 sec): n=1900, loss=0.521 (0.010), acc=0.855, f1=0.769
epoch 73: train (17.24 sec): n=85800, loss=0.210 (0.010), acc=0.928, f1=0.928 | valid (0.22 sec): n=1900, loss=0.490 (0.010), acc=0.864, f1=0.769
epoch 74: train (17.21 sec): n=85800, loss=0.212 (0.010), acc=0.927, f1=0.927 | valid (0.23 sec): n=1900, loss=0.533 (0.010), acc=0.853, f1=0.756
epoch 75: train (17.23 sec): n=85800, loss=0.208 (0.010), acc=0.928, f1=0.927 | valid (0.22 sec): n=1900, loss=0.516 (0.010), acc=0.866, f1=0.768
epoch 76: train (17.22 sec): n=85800, loss=0.205 (0.010), acc=0.930, f1=0.929 | valid (0.22 sec): n=1900, loss=0.528 (0.010), acc=0.848, f1=0.765
epoch 77: train (17.25 sec): n=85800, loss=0.203 (0.010), acc=0.930, f1=0.930 | valid (0.22 sec): n=1900, loss=0.515 (0.010), acc=0.858, f1=0.761
epoch 78: train (17.21 sec): n=85800, loss=0.198 (0.010), acc=0.931, f1=0.931 | valid (0.22 sec): n=1900, loss=0.507 (0.010), acc=0.859, f1=0.767
epoch 79: train (17.23 sec): n=85800, loss=0.199 (0.010), acc=0.931, f1=0.931 | valid (0.23 sec): n=1900, loss=0.550 (0.010), acc=0.852, f1=0.761
 
[2018-01-25 22:43:23.926709] epoch 80:
train (17.247 sec): n=85800, loss=0.196 (0.010), acc=0.932, f1=0.932
[[16407   419   102    21   208]
 [  268 16128   288     4   472]
 [  130   499 14975   682   872]
 [   18     8   518 16612     8]
 [  187   615   513     4 15842]]
valid (0.223 sec): n=1900, loss=0.523 (0.010), acc=0.863, f1=0.765
[[281  21   1   1   7]
 [ 17  24  16   3  57]
 [  4   5 529  33  44]
 [  1   0  23 493   0]
 [  7  12   8   0 313]]
 
epoch 81: train (17.23 sec): n=85800, loss=0.196 (0.010), acc=0.933, f1=0.932 | valid (0.22 sec): n=1900, loss=0.510 (0.010), acc=0.870, f1=0.777
epoch 82: train (17.21 sec): n=85800, loss=0.195 (0.009), acc=0.932, f1=0.932 | valid (0.23 sec): n=1900, loss=0.493 (0.009), acc=0.862, f1=0.774
epoch 83: train (17.24 sec): n=85800, loss=0.192 (0.009), acc=0.934, f1=0.934 | valid (0.22 sec): n=1900, loss=0.527 (0.009), acc=0.853, f1=0.770
epoch 84: train (17.24 sec): n=85800, loss=0.191 (0.009), acc=0.934, f1=0.934 | valid (0.22 sec): n=1900, loss=0.537 (0.009), acc=0.860, f1=0.766
epoch 85: train (17.22 sec): n=85800, loss=0.186 (0.009), acc=0.936, f1=0.936 | valid (0.23 sec): n=1900, loss=0.579 (0.009), acc=0.849, f1=0.759
epoch 86: train (17.27 sec): n=85800, loss=0.188 (0.009), acc=0.935, f1=0.935 | valid (0.23 sec): n=1900, loss=0.519 (0.009), acc=0.861, f1=0.767
epoch 87: train (17.18 sec): n=85800, loss=0.181 (0.009), acc=0.938, f1=0.938 | valid (0.23 sec): n=1900, loss=0.518 (0.009), acc=0.855, f1=0.766
epoch 88: train (17.23 sec): n=85800, loss=0.183 (0.009), acc=0.937, f1=0.936 | valid (0.23 sec): n=1900, loss=0.523 (0.009), acc=0.866, f1=0.768
epoch 89: train (17.23 sec): n=85800, loss=0.180 (0.009), acc=0.938, f1=0.938 | valid (0.22 sec): n=1900, loss=0.522 (0.009), acc=0.860, f1=0.768
 
[2018-01-25 22:46:25.326224] epoch 90:
train (17.252 sec): n=85800, loss=0.180 (0.009), acc=0.938, f1=0.938
[[16496   366    90    14   196]
 [  240 16243   266     4   408]
 [  110   463 15076   644   856]
 [   17     6   472 16664     6]
 [  158   522   493     3 15987]]
valid (0.235 sec): n=1900, loss=0.543 (0.009), acc=0.857, f1=0.769
[[267  32   2   1   9]
 [ 11  33  17   2  54]
 [  0   8 528  45  34]
 [  1   0  11 505   0]
 [  5  24  15   0 296]]
 
epoch 91: train (17.22 sec): n=85800, loss=0.176 (0.009), acc=0.939, f1=0.939 | valid (0.22 sec): n=1900, loss=0.546 (0.009), acc=0.856, f1=0.771
epoch 92: train (17.23 sec): n=85800, loss=0.175 (0.009), acc=0.941, f1=0.940 | valid (0.22 sec): n=1900, loss=0.603 (0.009), acc=0.859, f1=0.743
epoch 93: train (17.21 sec): n=85800, loss=0.177 (0.009), acc=0.939, f1=0.939 | valid (0.23 sec): n=1900, loss=0.556 (0.009), acc=0.862, f1=0.760
epoch 94: train (17.26 sec): n=85800, loss=0.173 (0.009), acc=0.941, f1=0.941 | valid (0.23 sec): n=1900, loss=0.592 (0.009), acc=0.849, f1=0.751
epoch 95: train (17.22 sec): n=85800, loss=0.168 (0.008), acc=0.942, f1=0.942 | valid (0.23 sec): n=1900, loss=0.519 (0.008), acc=0.866, f1=0.776
epoch 96: train (17.25 sec): n=85800, loss=0.170 (0.008), acc=0.942, f1=0.941 | valid (0.23 sec): n=1900, loss=0.544 (0.008), acc=0.864, f1=0.766
epoch 97: train (17.25 sec): n=85800, loss=0.168 (0.008), acc=0.942, f1=0.942 | valid (0.22 sec): n=1900, loss=0.578 (0.008), acc=0.854, f1=0.765
epoch 98: train (17.21 sec): n=85800, loss=0.169 (0.008), acc=0.941, f1=0.941 | valid (0.23 sec): n=1900, loss=0.528 (0.008), acc=0.863, f1=0.774
epoch 99: train (17.21 sec): n=85800, loss=0.165 (0.008), acc=0.944, f1=0.943 | valid (0.23 sec): n=1900, loss=0.587 (0.008), acc=0.852, f1=0.753
 
[2018-01-25 22:49:26.683984] epoch 100:
train (17.243 sec): n=85800, loss=0.161 (0.008), acc=0.944, f1=0.944
[[16563   315    99    13   172]
 [  189 16394   222     5   348]
 [  107   399 15244   608   799]
 [   15     4   426 16713     5]
 [  146   470   464     3 16077]]
valid (0.230 sec): n=1900, loss=0.567 (0.008), acc=0.861, f1=0.766
[[269  31   1   1   9]
 [ 11  27  19   0  60]
 [  2   5 532  44  32]
 [  1   0  12 504   0]
 [  2  15  19   0 304]]
 
Saved model checkpoint (0.581 sec)
Saved trained parameters (1.201 sec)
Finish pre-training
Network (layers=24)
inputs (x_train_inputs:0): (250, 3000, 1, 1)
targets (x_train_targets:0): (250,)
l1_conv (deepsleepnet/l1_conv/relu:0): (250, 500, 1, 64)
l2_pool (deepsleepnet/l2_pool:0): (250, 63, 1, 64)
l3_dropout (deepsleepnet/l3_dropout/mul:0): (250, 63, 1, 64)
l4_conv (deepsleepnet/l4_conv/relu:0): (250, 63, 1, 128)
l5_conv (deepsleepnet/l5_conv/relu:0): (250, 63, 1, 128)
l6_conv (deepsleepnet/l6_conv/relu:0): (250, 63, 1, 128)
l7_pool (deepsleepnet/l7_pool:0): (250, 16, 1, 128)
l8_flat (deepsleepnet/l8_flat:0): (250, 2048)
l9_conv (deepsleepnet/l9_conv/relu:0): (250, 60, 1, 64)
l10_pool (deepsleepnet/l10_pool:0): (250, 15, 1, 64)
l11_dropout (deepsleepnet/l11_dropout/mul:0): (250, 15, 1, 64)
l12_conv (deepsleepnet/l12_conv/relu:0): (250, 15, 1, 128)
l13_conv (deepsleepnet/l13_conv/relu:0): (250, 15, 1, 128)
l14_conv (deepsleepnet/l14_conv/relu:0): (250, 15, 1, 128)
l15_pool (deepsleepnet/l15_pool:0): (250, 8, 1, 128)
l16_flat (deepsleepnet/l16_flat:0): (250, 1024)
l17_concat (deepsleepnet/l17_concat:0): (250, 3072)
l18_dropout (deepsleepnet/l18_dropout/mul:0): (250, 3072)
l19_fc (deepsleepnet/l19_fc/relu:0): (250, 1024)
l20_reshape_seq (deepsleepnet/l20_reshape_seq:0): (10, 25, 3072)
l21_bi_lstm (deepsleepnet/l21_bi_lstm/l21_bi_lstm:0): (250, 1024)
l22_add (deepsleepnet/l22_add:0): (250, 1024)
l23_dropout (deepsleepnet/l23_dropout/mul:0): (250, 1024)
l24_softmax_linear (deepsleepnet/l24_softmax_linear/Add:0): (250, 5)
 
Loading pre-trained parameters to the model ...
 | --> deepfeaturenet from output/fold0/deepfeaturenet/params_fold0.npz
assigned deepfeaturenet/l1_conv/conv1d/weights:0: (50, 1, 1, 64) to deepsleepnet/l1_conv/conv1d/weights:0: (50, 1, 1, 64)
assigned deepfeaturenet/l5_conv/bn/moving_mean:0: (128,) to deepsleepnet/l5_conv/bn/moving_mean:0: (128,)
assigned deepfeaturenet/l6_conv/bn/moving_mean:0: (128,) to deepsleepnet/l6_conv/bn/moving_mean:0: (128,)
assigned deepfeaturenet/l4_conv/bn/beta:0: (128,) to deepsleepnet/l4_conv/bn/beta:0: (128,)
assigned deepfeaturenet/l9_conv/bn/moving_mean:0: (64,) to deepsleepnet/l9_conv/bn/moving_mean:0: (64,)
assigned deepfeaturenet/l14_conv/conv1d/weights:0: (6, 1, 128, 128) to deepsleepnet/l14_conv/conv1d/weights:0: (6, 1, 128, 128)
assigned deepfeaturenet/l5_conv/bn/gamma:0: (128,) to deepsleepnet/l5_conv/bn/gamma:0: (128,)
assigned deepfeaturenet/l4_conv/bn/gamma:0: (128,) to deepsleepnet/l4_conv/bn/gamma:0: (128,)
assigned deepfeaturenet/l9_conv/bn/moving_variance:0: (64,) to deepsleepnet/l9_conv/bn/moving_variance:0: (64,)
assigned deepfeaturenet/l9_conv/bn/beta:0: (64,) to deepsleepnet/l9_conv/bn/beta:0: (64,)
assigned deepfeaturenet/l6_conv/conv1d/weights:0: (8, 1, 128, 128) to deepsleepnet/l6_conv/conv1d/weights:0: (8, 1, 128, 128)
assigned deepfeaturenet/l4_conv/bn/moving_mean:0: (128,) to deepsleepnet/l4_conv/bn/moving_mean:0: (128,)
assigned deepfeaturenet/l13_conv/bn/moving_mean:0: (128,) to deepsleepnet/l13_conv/bn/moving_mean:0: (128,)
assigned deepfeaturenet/l13_conv/bn/gamma:0: (128,) to deepsleepnet/l13_conv/bn/gamma:0: (128,)
assigned deepfeaturenet/l1_conv/bn/gamma:0: (64,) to deepsleepnet/l1_conv/bn/gamma:0: (64,)
assigned deepfeaturenet/l9_conv/conv1d/weights:0: (400, 1, 1, 64) to deepsleepnet/l9_conv/conv1d/weights:0: (400, 1, 1, 64)
assigned deepfeaturenet/l6_conv/bn/moving_variance:0: (128,) to deepsleepnet/l6_conv/bn/moving_variance:0: (128,)
assigned deepfeaturenet/l6_conv/bn/gamma:0: (128,) to deepsleepnet/l6_conv/bn/gamma:0: (128,)
assigned deepfeaturenet/l13_conv/bn/moving_variance:0: (128,) to deepsleepnet/l13_conv/bn/moving_variance:0: (128,)
assigned deepfeaturenet/l4_conv/conv1d/weights:0: (8, 1, 64, 128) to deepsleepnet/l4_conv/conv1d/weights:0: (8, 1, 64, 128)
assigned deepfeaturenet/l5_conv/bn/moving_variance:0: (128,) to deepsleepnet/l5_conv/bn/moving_variance:0: (128,)
assigned deepfeaturenet/l9_conv/bn/gamma:0: (64,) to deepsleepnet/l9_conv/bn/gamma:0: (64,)
assigned deepfeaturenet/l1_conv/bn/moving_mean:0: (64,) to deepsleepnet/l1_conv/bn/moving_mean:0: (64,)
assigned deepfeaturenet/l4_conv/bn/moving_variance:0: (128,) to deepsleepnet/l4_conv/bn/moving_variance:0: (128,)
assigned deepfeaturenet/l1_conv/bn/moving_variance:0: (64,) to deepsleepnet/l1_conv/bn/moving_variance:0: (64,)
assigned deepfeaturenet/l13_conv/bn/beta:0: (128,) to deepsleepnet/l13_conv/bn/beta:0: (128,)
assigned deepfeaturenet/l12_conv/bn/moving_mean:0: (128,) to deepsleepnet/l12_conv/bn/moving_mean:0: (128,)
assigned deepfeaturenet/l14_conv/bn/beta:0: (128,) to deepsleepnet/l14_conv/bn/beta:0: (128,)
assigned deepfeaturenet/l14_conv/bn/gamma:0: (128,) to deepsleepnet/l14_conv/bn/gamma:0: (128,)
assigned deepfeaturenet/l14_conv/bn/moving_mean:0: (128,) to deepsleepnet/l14_conv/bn/moving_mean:0: (128,)
assigned deepfeaturenet/l13_conv/conv1d/weights:0: (6, 1, 128, 128) to deepsleepnet/l13_conv/conv1d/weights:0: (6, 1, 128, 128)
assigned deepfeaturenet/l5_conv/conv1d/weights:0: (8, 1, 128, 128) to deepsleepnet/l5_conv/conv1d/weights:0: (8, 1, 128, 128)
assigned deepfeaturenet/l12_conv/bn/beta:0: (128,) to deepsleepnet/l12_conv/bn/beta:0: (128,)
assigned deepfeaturenet/l12_conv/conv1d/weights:0: (6, 1, 64, 128) to deepsleepnet/l12_conv/conv1d/weights:0: (6, 1, 64, 128)
assigned deepfeaturenet/l1_conv/bn/beta:0: (64,) to deepsleepnet/l1_conv/bn/beta:0: (64,)
assigned deepfeaturenet/l6_conv/bn/beta:0: (128,) to deepsleepnet/l6_conv/bn/beta:0: (128,)
assigned deepfeaturenet/l12_conv/bn/gamma:0: (128,) to deepsleepnet/l12_conv/bn/gamma:0: (128,)
assigned deepfeaturenet/l14_conv/bn/moving_variance:0: (128,) to deepsleepnet/l14_conv/bn/moving_variance:0: (128,)
assigned deepfeaturenet/l12_conv/bn/moving_variance:0: (128,) to deepsleepnet/l12_conv/bn/moving_variance:0: (128,)
assigned deepfeaturenet/l5_conv/bn/beta:0: (128,) to deepsleepnet/l5_conv/bn/beta:0: (128,)
 
[2018-01-25 22:50:38.079456] Start fine-tuning ...


========== [Fold-0] ==========

Load training set:
Loading data/eeg_fpz_cz/SC4011E0.npz ...
Loading data/eeg_fpz_cz/SC4012E0.npz ...
Loading data/eeg_fpz_cz/SC4021E0.npz ...
Loading data/eeg_fpz_cz/SC4022E0.npz ...
Loading data/eeg_fpz_cz/SC4031E0.npz ...
Loading data/eeg_fpz_cz/SC4032E0.npz ...
Loading data/eeg_fpz_cz/SC4041E0.npz ...
Loading data/eeg_fpz_cz/SC4042E0.npz ...
Loading data/eeg_fpz_cz/SC4051E0.npz ...
Loading data/eeg_fpz_cz/SC4052E0.npz ...
Loading data/eeg_fpz_cz/SC4061E0.npz ...
Loading data/eeg_fpz_cz/SC4062E0.npz ...
Loading data/eeg_fpz_cz/SC4071E0.npz ...
Loading data/eeg_fpz_cz/SC4072E0.npz ...
Loading data/eeg_fpz_cz/SC4081E0.npz ...
Loading data/eeg_fpz_cz/SC4082E0.npz ...
Loading data/eeg_fpz_cz/SC4091E0.npz ...
Loading data/eeg_fpz_cz/SC4092E0.npz ...
Loading data/eeg_fpz_cz/SC4101E0.npz ...
Loading data/eeg_fpz_cz/SC4102E0.npz ...
Loading data/eeg_fpz_cz/SC4111E0.npz ...
Loading data/eeg_fpz_cz/SC4112E0.npz ...
Loading data/eeg_fpz_cz/SC4121E0.npz ...
Loading data/eeg_fpz_cz/SC4122E0.npz ...
Loading data/eeg_fpz_cz/SC4131E0.npz ...
Loading data/eeg_fpz_cz/SC4141E0.npz ...
Loading data/eeg_fpz_cz/SC4142E0.npz ...
Loading data/eeg_fpz_cz/SC4151E0.npz ...
Loading data/eeg_fpz_cz/SC4152E0.npz ...
Loading data/eeg_fpz_cz/SC4161E0.npz ...
Loading data/eeg_fpz_cz/SC4162E0.npz ...
Loading data/eeg_fpz_cz/SC4171E0.npz ...
Loading data/eeg_fpz_cz/SC4172E0.npz ...
Loading data/eeg_fpz_cz/SC4181E0.npz ...
Loading data/eeg_fpz_cz/SC4182E0.npz ...
Loading data/eeg_fpz_cz/SC4191E0.npz ...
Loading data/eeg_fpz_cz/SC4192E0.npz ...
 
Load validation set:
Loading data/eeg_fpz_cz/SC4001E0.npz ...
Loading data/eeg_fpz_cz/SC4002E0.npz ...
 
Training set: n_subjects=37
(1103, 3000, 1, 1)
(1186, 3000, 1, 1)
(1025, 3000, 1, 1)
(1009, 3000, 1, 1)
(952, 3000, 1, 1)
(911, 3000, 1, 1)
(1235, 3000, 1, 1)
(1200, 3000, 1, 1)
(672, 3000, 1, 1)
(1246, 3000, 1, 1)
(843, 3000, 1, 1)
(1016, 3000, 1, 1)
(976, 3000, 1, 1)
(1273, 3000, 1, 1)
(1134, 3000, 1, 1)
(1054, 3000, 1, 1)
(1132, 3000, 1, 1)
(1105, 3000, 1, 1)
(1104, 3000, 1, 1)
(1092, 3000, 1, 1)
(928, 3000, 1, 1)
(802, 3000, 1, 1)
(1052, 3000, 1, 1)
(977, 3000, 1, 1)
(1028, 3000, 1, 1)
(1004, 3000, 1, 1)
(952, 3000, 1, 1)
(952, 3000, 1, 1)
(1762, 3000, 1, 1)
(1144, 3000, 1, 1)
(1003, 3000, 1, 1)
(1002, 3000, 1, 1)
(1773, 3000, 1, 1)
(964, 3000, 1, 1)
(920, 3000, 1, 1)
(1535, 3000, 1, 1)
(1274, 3000, 1, 1)
Number of examples = 40340
W: 7914
N1: 2687
N2: 17176
N3: 5186
REM: 7377
 
Validation set: n_subjects=2
(841, 3000, 1, 1)
(1127, 3000, 1, 1)
Number of examples = 1968
W: 371
N1: 117
N2: 623
N3: 517
REM: 340
 
epoch 1: train (24.20 sec): n=36250, loss=15.340 (0.008), acc=0.793, f1=0.726 | valid (1.74 sec): n=1750, loss=14.534 (0.008), acc=0.846, f1=0.711
epoch 2: train (21.32 sec): n=36250, loss=11.291 (0.008), acc=0.848, f1=0.802 | valid (1.35 sec): n=1750, loss=13.515 (0.008), acc=0.855, f1=0.719
epoch 3: train (21.30 sec): n=36250, loss=10.014 (0.008), acc=0.863, f1=0.825 | valid (1.35 sec): n=1750, loss=12.290 (0.008), acc=0.868, f1=0.754
epoch 4: train (21.03 sec): n=36250, loss=9.188 (0.008), acc=0.874, f1=0.840 | valid (1.31 sec): n=1750, loss=12.098 (0.008), acc=0.867, f1=0.764
epoch 5: train (21.03 sec): n=36250, loss=8.693 (0.008), acc=0.878, f1=0.848 | valid (1.30 sec): n=1750, loss=11.808 (0.008), acc=0.874, f1=0.774
epoch 6: train (21.11 sec): n=36250, loss=8.390 (0.008), acc=0.882, f1=0.851 | valid (1.27 sec): n=1750, loss=11.327 (0.008), acc=0.877, f1=0.778
epoch 7: train (21.02 sec): n=36250, loss=7.992 (0.008), acc=0.888, f1=0.861 | valid (1.27 sec): n=1750, loss=10.808 (0.008), acc=0.881, f1=0.786
epoch 8: train (21.03 sec): n=36250, loss=7.609 (0.008), acc=0.893, f1=0.868 | valid (1.24 sec): n=1750, loss=10.448 (0.008), acc=0.882, f1=0.794
epoch 9: train (21.05 sec): n=36250, loss=7.403 (0.008), acc=0.894, f1=0.869 | valid (1.28 sec): n=1750, loss=10.713 (0.008), acc=0.882, f1=0.784
 
[2018-01-25 22:54:45.333757] epoch 10:
train (21.194 sec): n=36250, loss=7.227 (0.008), acc=0.898, f1=0.874
[[ 6754   154   131     8    44]
 [  188  1729   396     3   104]
 [  113   230 14012   690   424]
 [   10     6   674  4009     0]
 [   28    92   410     3  6038]]
valid (1.237 sec): n=1750, loss=10.323 (0.008), acc=0.882, f1=0.801
[[296  24   3   1   5]
 [  8  31  36   3  31]
 [  1   1 490  50  14]
 [  0   0   9 450   0]
 [  0   3  17   0 277]]
 
epoch 11: train (21.37 sec): n=36250, loss=6.951 (0.008), acc=0.900, f1=0.877 | valid (1.24 sec): n=1750, loss=10.255 (0.008), acc=0.883, f1=0.801
epoch 12: train (21.31 sec): n=36250, loss=6.874 (0.008), acc=0.901, f1=0.879 | valid (1.24 sec): n=1750, loss=10.326 (0.008), acc=0.884, f1=0.807
epoch 13: train (21.53 sec): n=36250, loss=6.669 (0.008), acc=0.903, f1=0.881 | valid (1.26 sec): n=1750, loss=10.277 (0.008), acc=0.880, f1=0.803
epoch 14: train (21.50 sec): n=36250, loss=6.526 (0.008), acc=0.907, f1=0.886 | valid (1.27 sec): n=1750, loss=10.084 (0.008), acc=0.879, f1=0.804
epoch 15: train (21.11 sec): n=36250, loss=6.323 (0.008), acc=0.908, f1=0.889 | valid (1.24 sec): n=1750, loss=10.024 (0.008), acc=0.879, f1=0.801
epoch 16: train (21.30 sec): n=36250, loss=6.233 (0.008), acc=0.909, f1=0.889 | valid (1.26 sec): n=1750, loss=10.049 (0.008), acc=0.885, f1=0.807
epoch 17: train (21.38 sec): n=36250, loss=6.119 (0.008), acc=0.911, f1=0.892 | valid (1.30 sec): n=1750, loss=9.921 (0.008), acc=0.881, f1=0.803
epoch 18: train (21.52 sec): n=36250, loss=6.000 (0.008), acc=0.912, f1=0.893 | valid (1.24 sec): n=1750, loss=10.215 (0.008), acc=0.875, f1=0.798
epoch 19: train (21.35 sec): n=36250, loss=5.829 (0.008), acc=0.915, f1=0.897 | valid (1.28 sec): n=1750, loss=9.812 (0.008), acc=0.882, f1=0.806
 
[2018-01-25 22:58:50.137190] epoch 20:
train (21.520 sec): n=36250, loss=5.752 (0.008), acc=0.914, f1=0.895
[[ 6826   123   103    13    26]
 [  133  1860   342     0    85]
 [   85   190 14196   672   326]
 [   14     3   605  4077     0]
 [   22    68   301     1  6179]]
valid (1.276 sec): n=1750, loss=10.094 (0.008), acc=0.877, f1=0.800
[[294  26   4   1   4]
 [ 11  33  37   2  26]
 [  0   3 488  58   7]
 [  0   0   7 452   0]
 [  0   3  27   0 267]]
 
epoch 21: train (21.61 sec): n=36250, loss=5.633 (0.008), acc=0.916, f1=0.898 | valid (1.27 sec): n=1750, loss=10.339 (0.008), acc=0.885, f1=0.806
epoch 22: train (21.40 sec): n=36250, loss=5.562 (0.008), acc=0.918, f1=0.902 | valid (1.24 sec): n=1750, loss=9.693 (0.008), acc=0.882, f1=0.811
epoch 23: train (21.04 sec): n=36250, loss=5.320 (0.008), acc=0.921, f1=0.906 | valid (1.24 sec): n=1750, loss=9.860 (0.008), acc=0.887, f1=0.815
epoch 24: train (21.49 sec): n=36250, loss=5.196 (0.008), acc=0.923, f1=0.908 | valid (1.24 sec): n=1750, loss=10.073 (0.008), acc=0.886, f1=0.811
epoch 25: train (21.06 sec): n=36250, loss=5.294 (0.008), acc=0.924, f1=0.910 | valid (1.24 sec): n=1750, loss=9.980 (0.008), acc=0.885, f1=0.809
epoch 26: train (21.08 sec): n=36250, loss=5.096 (0.008), acc=0.925, f1=0.911 | valid (1.24 sec): n=1750, loss=10.811 (0.008), acc=0.889, f1=0.807
epoch 27: train (21.21 sec): n=36250, loss=4.993 (0.008), acc=0.925, f1=0.911 | valid (1.26 sec): n=1750, loss=10.148 (0.008), acc=0.894, f1=0.815
epoch 28: train (21.55 sec): n=36250, loss=5.000 (0.008), acc=0.926, f1=0.911 | valid (1.28 sec): n=1750, loss=10.968 (0.008), acc=0.885, f1=0.798
epoch 29: train (21.51 sec): n=36250, loss=4.975 (0.008), acc=0.927, f1=0.912 | valid (1.27 sec): n=1750, loss=10.219 (0.008), acc=0.878, f1=0.809
 
[2018-01-25 23:02:54.216597] epoch 30:
train (21.327 sec): n=36250, loss=4.853 (0.008), acc=0.928, f1=0.914
[[ 6894   104    71     5    17]
 [  110  1988   273     0    49]
 [   67   149 14373   642   238]
 [   12     2   558  4126     1]
 [   20    44   235     0  6272]]
valid (1.239 sec): n=1750, loss=10.495 (0.008), acc=0.883, f1=0.803
[[295  25   4   1   4]
 [ 11  32  38   2  26]
 [  0   4 502  43   7]
 [  0   0  10 449   0]
 [  0   3  26   0 268]]
 
epoch 31: train (21.05 sec): n=36250, loss=4.687 (0.008), acc=0.931, f1=0.919 | valid (1.24 sec): n=1750, loss=10.695 (0.008), acc=0.889, f1=0.803
epoch 32: train (21.00 sec): n=36250, loss=4.698 (0.008), acc=0.931, f1=0.917 | valid (1.24 sec): n=1750, loss=10.948 (0.008), acc=0.881, f1=0.797
epoch 33: train (21.02 sec): n=36250, loss=4.503 (0.008), acc=0.933, f1=0.920 | valid (1.25 sec): n=1750, loss=10.743 (0.008), acc=0.878, f1=0.803
epoch 34: train (21.21 sec): n=36250, loss=4.558 (0.008), acc=0.933, f1=0.920 | valid (1.25 sec): n=1750, loss=11.117 (0.008), acc=0.886, f1=0.801
epoch 35: train (21.06 sec): n=36250, loss=4.435 (0.008), acc=0.934, f1=0.921 | valid (1.25 sec): n=1750, loss=10.669 (0.008), acc=0.889, f1=0.802
epoch 36: train (21.12 sec): n=36250, loss=4.318 (0.008), acc=0.935, f1=0.922 | valid (1.26 sec): n=1750, loss=10.633 (0.008), acc=0.886, f1=0.799
epoch 37: train (21.37 sec): n=36250, loss=4.123 (0.008), acc=0.938, f1=0.926 | valid (1.29 sec): n=1750, loss=11.363 (0.008), acc=0.883, f1=0.802
epoch 38: train (21.57 sec): n=36250, loss=4.204 (0.008), acc=0.937, f1=0.924 | valid (1.27 sec): n=1750, loss=10.488 (0.008), acc=0.888, f1=0.821
epoch 39: train (21.60 sec): n=36250, loss=4.148 (0.008), acc=0.938, f1=0.924 | valid (1.29 sec): n=1750, loss=10.833 (0.008), acc=0.883, f1=0.803
 
[2018-01-25 23:06:57.002704] epoch 40:
train (21.015 sec): n=36250, loss=4.103 (0.008), acc=0.940, f1=0.927
[[ 6920    92    54     9    16]
 [  100  2053   226     5    36]
 [   51   114 14535   590   179]
 [    3     2   495  4196     3]
 [   20    37   138     1  6375]]
valid (1.245 sec): n=1750, loss=10.676 (0.008), acc=0.891, f1=0.814
[[298  22   4   1   4]
 [  8  34  32   3  32]
 [  0   4 500  37  15]
 [  0   0  17 442   0]
 [  0   1  11   0 285]]
 
epoch 41: train (21.42 sec): n=36250, loss=4.032 (0.008), acc=0.940, f1=0.927 | valid (1.28 sec): n=1750, loss=11.006 (0.008), acc=0.883, f1=0.804
epoch 42: train (21.13 sec): n=36250, loss=3.877 (0.008), acc=0.942, f1=0.931 | valid (1.24 sec): n=1750, loss=11.604 (0.008), acc=0.886, f1=0.806
epoch 43: train (21.11 sec): n=36250, loss=3.852 (0.008), acc=0.942, f1=0.931 | valid (1.25 sec): n=1750, loss=11.576 (0.008), acc=0.883, f1=0.798
epoch 44: train (21.41 sec): n=36250, loss=3.865 (0.008), acc=0.942, f1=0.932 | valid (1.28 sec): n=1750, loss=11.554 (0.008), acc=0.884, f1=0.805
epoch 45: train (21.56 sec): n=36250, loss=3.802 (0.008), acc=0.944, f1=0.934 | valid (1.31 sec): n=1750, loss=11.326 (0.008), acc=0.885, f1=0.805
epoch 46: train (21.59 sec): n=36250, loss=3.770 (0.008), acc=0.944, f1=0.933 | valid (1.28 sec): n=1750, loss=11.598 (0.008), acc=0.881, f1=0.793
epoch 47: train (21.34 sec): n=36250, loss=3.739 (0.008), acc=0.945, f1=0.934 | valid (1.25 sec): n=1750, loss=11.487 (0.008), acc=0.877, f1=0.806
epoch 48: train (21.01 sec): n=36250, loss=3.561 (0.008), acc=0.947, f1=0.936 | valid (1.24 sec): n=1750, loss=11.655 (0.008), acc=0.877, f1=0.797
epoch 49: train (21.08 sec): n=36250, loss=3.570 (0.008), acc=0.947, f1=0.937 | valid (1.31 sec): n=1750, loss=11.921 (0.008), acc=0.879, f1=0.800
 
[2018-01-25 23:11:01.183077] epoch 50:
train (21.319 sec): n=36250, loss=3.438 (0.008), acc=0.948, f1=0.938
[[ 6944    89    47     2     9]
 [   69  2139   178     1    33]
 [   38   106 14615   544   166]
 [    3     1   435  4258     2]
 [   13    26   133     0  6399]]
valid (1.251 sec): n=1750, loss=11.930 (0.008), acc=0.879, f1=0.795
[[295  25   4   1   4]
 [ 10  28  37   2  32]
 [  0   2 495  49  10]
 [  0   0  14 445   0]
 [  0   0  21   0 276]]
 
epoch 51: train (21.30 sec): n=36250, loss=3.483 (0.008), acc=0.947, f1=0.937 | valid (1.28 sec): n=1750, loss=11.567 (0.008), acc=0.885, f1=0.815
epoch 52: train (21.37 sec): n=36250, loss=3.357 (0.008), acc=0.949, f1=0.940 | valid (1.25 sec): n=1750, loss=11.169 (0.008), acc=0.875, f1=0.807
epoch 53: train (21.33 sec): n=36250, loss=3.312 (0.008), acc=0.949, f1=0.939 | valid (1.25 sec): n=1750, loss=11.689 (0.008), acc=0.884, f1=0.808
epoch 54: train (21.52 sec): n=36250, loss=3.233 (0.008), acc=0.952, f1=0.943 | valid (1.25 sec): n=1750, loss=12.543 (0.008), acc=0.885, f1=0.801
epoch 55: train (21.37 sec): n=36250, loss=3.160 (0.008), acc=0.952, f1=0.942 | valid (1.28 sec): n=1750, loss=12.136 (0.008), acc=0.875, f1=0.796
epoch 56: train (21.07 sec): n=36250, loss=3.220 (0.008), acc=0.952, f1=0.942 | valid (1.25 sec): n=1750, loss=12.034 (0.008), acc=0.878, f1=0.807
epoch 57: train (21.00 sec): n=36250, loss=3.214 (0.008), acc=0.952, f1=0.943 | valid (1.26 sec): n=1750, loss=12.410 (0.008), acc=0.882, f1=0.794
epoch 58: train (21.50 sec): n=36250, loss=3.125 (0.008), acc=0.953, f1=0.944 | valid (1.26 sec): n=1750, loss=11.463 (0.008), acc=0.885, f1=0.806
epoch 59: train (21.00 sec): n=36250, loss=3.149 (0.008), acc=0.952, f1=0.942 | valid (1.25 sec): n=1750, loss=12.050 (0.008), acc=0.881, f1=0.800
 
[2018-01-25 23:15:14.333921] epoch 60:
train (21.328 sec): n=36250, loss=3.110 (0.008), acc=0.953, f1=0.942
[[ 6955    82    36     3    15]
 [   80  2146   152     1    41]
 [   47   102 14712   481   127]
 [    2     1   398  4298     0]
 [    6    30   116     1  6418]]
valid (1.258 sec): n=1750, loss=12.613 (0.008), acc=0.878, f1=0.795
[[298  21   5   1   4]
 [  7  27  50   3  22]
 [  0   1 508  43   4]
 [  0   0  19 440   0]
 [  0   0  33   0 264]]
 
epoch 61: train (21.58 sec): n=36250, loss=3.004 (0.008), acc=0.955, f1=0.945 | valid (1.31 sec): n=1750, loss=12.494 (0.008), acc=0.882, f1=0.810
epoch 62: train (21.53 sec): n=36250, loss=3.034 (0.008), acc=0.954, f1=0.944 | valid (1.26 sec): n=1750, loss=12.460 (0.008), acc=0.883, f1=0.797
epoch 63: train (21.48 sec): n=36250, loss=2.980 (0.008), acc=0.955, f1=0.946 | valid (1.25 sec): n=1750, loss=12.916 (0.008), acc=0.875, f1=0.798
epoch 64: train (21.19 sec): n=36250, loss=2.864 (0.008), acc=0.957, f1=0.948 | valid (1.25 sec): n=1750, loss=13.039 (0.008), acc=0.878, f1=0.791
epoch 65: train (21.55 sec): n=36250, loss=2.875 (0.008), acc=0.956, f1=0.947 | valid (1.30 sec): n=1750, loss=12.478 (0.008), acc=0.875, f1=0.795
epoch 66: train (21.33 sec): n=36250, loss=2.937 (0.008), acc=0.954, f1=0.945 | valid (1.29 sec): n=1750, loss=13.047 (0.008), acc=0.878, f1=0.798
epoch 67: train (21.48 sec): n=36250, loss=2.838 (0.008), acc=0.957, f1=0.949 | valid (1.29 sec): n=1750, loss=12.486 (0.008), acc=0.882, f1=0.806
epoch 68: train (21.42 sec): n=36250, loss=2.746 (0.008), acc=0.958, f1=0.950 | valid (1.27 sec): n=1750, loss=12.340 (0.008), acc=0.879, f1=0.799
epoch 69: train (21.23 sec): n=36250, loss=2.616 (0.008), acc=0.958, f1=0.950 | valid (1.25 sec): n=1750, loss=12.703 (0.008), acc=0.879, f1=0.797
 
[2018-01-25 23:19:19.909602] epoch 70:
train (21.455 sec): n=36250, loss=2.632 (0.008), acc=0.960, f1=0.952
[[ 6991    63    21     5    11]
 [   53  2209   127     1    30]
 [   30   101 14828   396   114]
 [    5     1   379  4314     0]
 [   12    21    78     0  6460]]
valid (1.249 sec): n=1750, loss=12.490 (0.008), acc=0.874, f1=0.791
[[301  19   4   1   4]
 [  9  27  42   2  29]
 [  0   3 489  59   5]
 [  0   0  17 442   0]
 [  0   0  27   0 270]]
 
epoch 71: train (21.55 sec): n=36250, loss=2.732 (0.008), acc=0.959, f1=0.950 | valid (1.27 sec): n=1750, loss=12.832 (0.008), acc=0.881, f1=0.798
epoch 72: train (21.59 sec): n=36250, loss=2.694 (0.008), acc=0.959, f1=0.951 | valid (1.26 sec): n=1750, loss=13.612 (0.008), acc=0.882, f1=0.791
epoch 73: train (21.41 sec): n=36250, loss=2.689 (0.008), acc=0.960, f1=0.952 | valid (1.27 sec): n=1750, loss=13.142 (0.008), acc=0.874, f1=0.791
epoch 74: train (21.48 sec): n=36250, loss=2.626 (0.008), acc=0.961, f1=0.953 | valid (1.25 sec): n=1750, loss=13.017 (0.008), acc=0.878, f1=0.797
epoch 75: train (21.39 sec): n=36250, loss=2.491 (0.008), acc=0.962, f1=0.954 | valid (1.26 sec): n=1750, loss=13.370 (0.008), acc=0.882, f1=0.799
epoch 76: train (21.40 sec): n=36250, loss=2.679 (0.008), acc=0.959, f1=0.950 | valid (1.25 sec): n=1750, loss=12.572 (0.008), acc=0.870, f1=0.800
epoch 77: train (21.02 sec): n=36250, loss=2.583 (0.008), acc=0.961, f1=0.953 | valid (1.25 sec): n=1750, loss=12.392 (0.008), acc=0.884, f1=0.801
epoch 78: train (21.02 sec): n=36250, loss=2.491 (0.008), acc=0.962, f1=0.954 | valid (1.25 sec): n=1750, loss=14.484 (0.008), acc=0.875, f1=0.795
epoch 79: train (21.19 sec): n=36250, loss=2.511 (0.008), acc=0.963, f1=0.955 | valid (1.25 sec): n=1750, loss=13.028 (0.008), acc=0.882, f1=0.794
 
[2018-01-25 23:23:24.554382] epoch 80:
train (21.521 sec): n=36250, loss=2.524 (0.008), acc=0.962, f1=0.954
[[ 6980    74    26     1    10]
 [   50  2222   123     0    25]
 [   24    85 14841   408   111]
 [    1     0   352  4346     0]
 [    6    16    81     1  6467]]
valid (1.276 sec): n=1750, loss=15.095 (0.008), acc=0.867, f1=0.781
[[302  14   8   1   4]
 [ 12  24  55   2  16]
 [  1   1 508  42   4]
 [  0   0  19 440   0]
 [  0   0  54   0 243]]
 
epoch 81: train (21.09 sec): n=36250, loss=2.528 (0.008), acc=0.962, f1=0.955 | valid (1.25 sec): n=1750, loss=14.036 (0.008), acc=0.870, f1=0.788
epoch 82: train (21.05 sec): n=36250, loss=2.471 (0.008), acc=0.962, f1=0.954 | valid (1.25 sec): n=1750, loss=13.296 (0.008), acc=0.879, f1=0.791
epoch 83: train (21.17 sec): n=36250, loss=2.312 (0.008), acc=0.965, f1=0.958 | valid (1.25 sec): n=1750, loss=13.730 (0.008), acc=0.883, f1=0.800
epoch 84: train (21.27 sec): n=36250, loss=2.451 (0.008), acc=0.963, f1=0.956 | valid (1.25 sec): n=1750, loss=15.381 (0.008), acc=0.866, f1=0.778
epoch 85: train (21.23 sec): n=36250, loss=2.358 (0.008), acc=0.965, f1=0.957 | valid (1.26 sec): n=1750, loss=14.329 (0.008), acc=0.874, f1=0.787
epoch 86: train (21.54 sec): n=36250, loss=2.278 (0.008), acc=0.966, f1=0.958 | valid (1.26 sec): n=1750, loss=14.929 (0.008), acc=0.863, f1=0.778
epoch 87: train (21.41 sec): n=36250, loss=2.205 (0.008), acc=0.966, f1=0.959 | valid (1.26 sec): n=1750, loss=13.674 (0.008), acc=0.880, f1=0.803
epoch 88: train (21.11 sec): n=36250, loss=2.111 (0.008), acc=0.968, f1=0.962 | valid (1.28 sec): n=1750, loss=12.865 (0.008), acc=0.887, f1=0.799
epoch 89: train (21.22 sec): n=36250, loss=2.132 (0.008), acc=0.968, f1=0.961 | valid (1.31 sec): n=1750, loss=13.474 (0.008), acc=0.880, f1=0.795
 
[2018-01-25 23:27:28.155853] epoch 90:
train (21.428 sec): n=36250, loss=2.265 (0.008), acc=0.966, f1=0.960
[[ 7015    53    18     2     3]
 [   48  2243   100     0    29]
 [   22    73 14898   390    86]
 [    0     0   284  4414     1]
 [   12    17    94     1  6447]]
valid (1.315 sec): n=1750, loss=13.324 (0.008), acc=0.888, f1=0.803
[[298  19   7   1   4]
 [ 12  28  45   2  22]
 [  0   1 525  26   4]
 [  0   0  23 436   0]
 [  0   0  30   0 267]]
 
epoch 91: train (21.42 sec): n=36250, loss=2.146 (0.008), acc=0.968, f1=0.961 | valid (1.31 sec): n=1750, loss=13.920 (0.008), acc=0.882, f1=0.786
epoch 92: train (21.28 sec): n=36250, loss=2.172 (0.008), acc=0.966, f1=0.959 | valid (1.26 sec): n=1750, loss=15.901 (0.008), acc=0.862, f1=0.783
epoch 93: train (21.34 sec): n=36250, loss=2.221 (0.008), acc=0.966, f1=0.959 | valid (1.28 sec): n=1750, loss=16.221 (0.008), acc=0.870, f1=0.780
epoch 94: train (21.04 sec): n=36250, loss=2.154 (0.008), acc=0.967, f1=0.960 | valid (1.29 sec): n=1750, loss=13.819 (0.008), acc=0.881, f1=0.793
epoch 95: train (21.54 sec): n=36250, loss=2.093 (0.008), acc=0.969, f1=0.963 | valid (1.30 sec): n=1750, loss=13.519 (0.008), acc=0.879, f1=0.799
epoch 96: train (21.47 sec): n=36250, loss=2.029 (0.008), acc=0.970, f1=0.963 | valid (1.28 sec): n=1750, loss=13.938 (0.008), acc=0.882, f1=0.805
epoch 97: train (21.56 sec): n=36250, loss=1.949 (0.008), acc=0.970, f1=0.964 | valid (1.30 sec): n=1750, loss=15.522 (0.008), acc=0.872, f1=0.792
epoch 98: train (21.40 sec): n=36250, loss=2.036 (0.008), acc=0.969, f1=0.963 | valid (1.25 sec): n=1750, loss=14.645 (0.008), acc=0.882, f1=0.799
epoch 99: train (21.04 sec): n=36250, loss=1.995 (0.008), acc=0.971, f1=0.964 | valid (1.26 sec): n=1750, loss=15.535 (0.008), acc=0.877, f1=0.787
 
[2018-01-25 23:31:32.533420] epoch 100:
train (21.038 sec): n=36250, loss=1.921 (0.008), acc=0.971, f1=0.964
[[ 7028    37    22     1     3]
 [   43  2247   105     0    25]
 [   18    72 15017   300    62]
 [    1     2   271  4423     2]
 [    4    20    70     2  6475]]
valid (1.254 sec): n=1750, loss=15.648 (0.008), acc=0.873, f1=0.793
[[299  19   6   1   4]
 [ 11  29  49   2  18]
 [  0   2 524  26   4]
 [  0   0  29 430   0]
 [  0   1  50   0 246]]
 
Saved model checkpoint (3.868 sec)
Saved trained parameters (16.515 sec)
epoch 101: train (21.24 sec): n=36250, loss=1.924 (0.008), acc=0.970, f1=0.964 | valid (1.29 sec): n=1750, loss=15.049 (0.008), acc=0.874, f1=0.795
epoch 102: train (21.35 sec): n=36250, loss=1.944 (0.008), acc=0.971, f1=0.965 | valid (1.26 sec): n=1750, loss=14.208 (0.008), acc=0.885, f1=0.801
epoch 103: train (21.47 sec): n=36250, loss=2.059 (0.008), acc=0.970, f1=0.964 | valid (1.31 sec): n=1750, loss=14.375 (0.008), acc=0.879, f1=0.790
epoch 104: train (21.52 sec): n=36250, loss=1.931 (0.008), acc=0.972, f1=0.967 | valid (1.31 sec): n=1750, loss=12.924 (0.008), acc=0.889, f1=0.809
epoch 105: train (21.42 sec): n=36250, loss=1.903 (0.008), acc=0.971, f1=0.966 | valid (1.26 sec): n=1750, loss=14.348 (0.008), acc=0.889, f1=0.799
epoch 106: train (21.05 sec): n=36250, loss=1.912 (0.008), acc=0.971, f1=0.965 | valid (1.26 sec): n=1750, loss=14.896 (0.008), acc=0.877, f1=0.787
epoch 107: train (21.04 sec): n=36250, loss=1.762 (0.008), acc=0.972, f1=0.966 | valid (1.29 sec): n=1750, loss=13.895 (0.008), acc=0.874, f1=0.795
epoch 108: train (21.15 sec): n=36250, loss=1.773 (0.008), acc=0.973, f1=0.967 | valid (1.26 sec): n=1750, loss=16.138 (0.008), acc=0.879, f1=0.788
epoch 109: train (21.03 sec): n=36250, loss=1.901 (0.008), acc=0.972, f1=0.966 | valid (1.26 sec): n=1750, loss=14.427 (0.008), acc=0.888, f1=0.804
 
[2018-01-25 23:36:00.162457] epoch 110:
train (21.032 sec): n=36250, loss=1.767 (0.008), acc=0.973, f1=0.968
[[ 7036    35    14     1     5]
 [   44  2273    84     0    19]
 [   14    68 15029   296    62]
 [    3     0   253  4439     4]
 [    4    11    50     2  6504]]
valid (1.257 sec): n=1750, loss=14.043 (0.008), acc=0.889, f1=0.796
[[303  16   5   1   4]
 [ 13  23  41   2  30]
 [  1   0 527  21   7]
 [  0   0  38 421   0]
 [  0   0  16   0 281]]
 
epoch 111: train (21.04 sec): n=36250, loss=1.862 (0.008), acc=0.973, f1=0.967 | valid (1.26 sec): n=1750, loss=14.308 (0.008), acc=0.887, f1=0.803
epoch 112: train (21.25 sec): n=36250, loss=1.789 (0.008), acc=0.973, f1=0.967 | valid (1.31 sec): n=1750, loss=15.008 (0.008), acc=0.889, f1=0.803
epoch 113: train (21.52 sec): n=36250, loss=1.888 (0.008), acc=0.970, f1=0.964 | valid (1.30 sec): n=1750, loss=15.005 (0.008), acc=0.878, f1=0.796
epoch 114: train (21.61 sec): n=36250, loss=1.764 (0.008), acc=0.973, f1=0.967 | valid (1.29 sec): n=1750, loss=14.856 (0.008), acc=0.892, f1=0.807
epoch 115: train (21.61 sec): n=36250, loss=1.743 (0.008), acc=0.974, f1=0.969 | valid (1.28 sec): n=1750, loss=14.040 (0.008), acc=0.892, f1=0.808
epoch 116: train (21.55 sec): n=36250, loss=1.735 (0.008), acc=0.973, f1=0.968 | valid (1.32 sec): n=1750, loss=13.967 (0.008), acc=0.896, f1=0.814
epoch 117: train (21.38 sec): n=36250, loss=1.675 (0.008), acc=0.974, f1=0.969 | valid (1.28 sec): n=1750, loss=14.876 (0.008), acc=0.893, f1=0.795
epoch 118: train (21.24 sec): n=36250, loss=1.757 (0.008), acc=0.974, f1=0.968 | valid (1.25 sec): n=1750, loss=14.682 (0.008), acc=0.882, f1=0.799
epoch 119: train (21.13 sec): n=36250, loss=1.622 (0.008), acc=0.976, f1=0.971 | valid (1.25 sec): n=1750, loss=14.424 (0.008), acc=0.890, f1=0.795
 
[2018-01-25 23:40:05.142709] epoch 120:
train (21.112 sec): n=36250, loss=1.595 (0.008), acc=0.977, f1=0.972
[[ 7026    44    16     1     4]
 [   42  2296    62     0    20]
 [   13    49 15100   255    52]
 [    3     0   228  4466     2]
 [    2    11    41     2  6515]]
valid (1.260 sec): n=1750, loss=14.365 (0.008), acc=0.889, f1=0.801
[[305  15   4   1   4]
 [ 13  26  42   2  26]
 [  1   1 519  28   7]
 [  0   0  25 434   0]
 [  0   1  25   0 271]]
 
epoch 121: train (21.16 sec): n=36250, loss=1.649 (0.008), acc=0.976, f1=0.971 | valid (1.27 sec): n=1750, loss=13.675 (0.008), acc=0.891, f1=0.813
epoch 122: train (21.29 sec): n=36250, loss=1.586 (0.008), acc=0.975, f1=0.970 | valid (1.25 sec): n=1750, loss=15.135 (0.008), acc=0.886, f1=0.806
epoch 123: train (21.03 sec): n=36250, loss=1.646 (0.008), acc=0.975, f1=0.969 | valid (1.26 sec): n=1750, loss=14.350 (0.008), acc=0.888, f1=0.810
epoch 124: train (21.04 sec): n=36250, loss=1.596 (0.008), acc=0.976, f1=0.971 | valid (1.26 sec): n=1750, loss=16.711 (0.008), acc=0.881, f1=0.800
epoch 125: train (21.09 sec): n=36250, loss=1.569 (0.008), acc=0.977, f1=0.972 | valid (1.30 sec): n=1750, loss=15.427 (0.008), acc=0.890, f1=0.798
epoch 126: train (21.60 sec): n=36250, loss=1.542 (0.008), acc=0.976, f1=0.972 | valid (1.27 sec): n=1750, loss=15.451 (0.008), acc=0.883, f1=0.799
epoch 127: train (21.56 sec): n=36250, loss=1.609 (0.008), acc=0.976, f1=0.971 | valid (1.28 sec): n=1750, loss=15.148 (0.008), acc=0.890, f1=0.807
epoch 128: train (21.26 sec): n=36250, loss=1.563 (0.008), acc=0.976, f1=0.971 | valid (1.25 sec): n=1750, loss=15.083 (0.008), acc=0.883, f1=0.799
epoch 129: train (21.03 sec): n=36250, loss=1.561 (0.008), acc=0.976, f1=0.971 | valid (1.26 sec): n=1750, loss=15.725 (0.008), acc=0.887, f1=0.802
 
[2018-01-25 23:44:08.929021] epoch 130:
train (21.338 sec): n=36250, loss=1.474 (0.008), acc=0.978, f1=0.974
[[ 7044    30    12     1     4]
 [   26  2319    61     0    14]
 [   12    60 15115   234    48]
 [    2     1   216  4480     0]
 [    3    18    48     1  6501]]
valid (1.319 sec): n=1750, loss=15.743 (0.008), acc=0.886, f1=0.788
[[304  15   5   1   4]
 [ 11  21  40   2  35]
 [  0   1 509  33  13]
 [  0   0  20 439   0]
 [  0   0  20   0 277]]
 
epoch 131: train (21.55 sec): n=36250, loss=1.533 (0.008), acc=0.977, f1=0.972 | valid (1.30 sec): n=1750, loss=14.819 (0.008), acc=0.896, f1=0.807
epoch 132: train (21.25 sec): n=36250, loss=1.441 (0.008), acc=0.979, f1=0.974 | valid (1.30 sec): n=1750, loss=15.809 (0.008), acc=0.882, f1=0.804
epoch 133: train (21.02 sec): n=36250, loss=1.412 (0.008), acc=0.979, f1=0.974 | valid (1.27 sec): n=1750, loss=16.078 (0.008), acc=0.889, f1=0.798
epoch 134: train (21.57 sec): n=36250, loss=1.516 (0.008), acc=0.977, f1=0.972 | valid (1.31 sec): n=1750, loss=15.651 (0.008), acc=0.891, f1=0.799
epoch 135: train (21.49 sec): n=36250, loss=1.441 (0.008), acc=0.979, f1=0.974 | valid (1.26 sec): n=1750, loss=15.676 (0.008), acc=0.887, f1=0.806
epoch 136: train (21.22 sec): n=36250, loss=1.387 (0.008), acc=0.978, f1=0.974 | valid (1.26 sec): n=1750, loss=15.163 (0.008), acc=0.894, f1=0.814
epoch 137: train (21.17 sec): n=36250, loss=1.390 (0.008), acc=0.979, f1=0.975 | valid (1.27 sec): n=1750, loss=15.940 (0.008), acc=0.890, f1=0.791
epoch 138: train (21.57 sec): n=36250, loss=1.462 (0.008), acc=0.979, f1=0.974 | valid (1.28 sec): n=1750, loss=16.891 (0.008), acc=0.881, f1=0.786
epoch 139: train (21.44 sec): n=36250, loss=1.391 (0.008), acc=0.980, f1=0.975 | valid (1.31 sec): n=1750, loss=15.419 (0.008), acc=0.894, f1=0.812
 
[2018-01-25 23:48:13.918166] epoch 140:
train (21.169 sec): n=36250, loss=1.454 (0.008), acc=0.978, f1=0.974
[[ 7042    30    13     0     6]
 [   45  2303    61     0    11]
 [   13    56 15119   222    59]
 [    0     0   214  4485     0]
 [    5     4    47     0  6515]]
valid (1.282 sec): n=1750, loss=15.754 (0.008), acc=0.881, f1=0.786
[[305  14   5   1   4]
 [ 13  21  41   2  32]
 [  0   0 509  38   9]
 [  0   0  27 432   0]
 [  0   0  22   0 275]]
 
epoch 141: train (21.21 sec): n=36250, loss=1.313 (0.008), acc=0.980, f1=0.976 | valid (1.34 sec): n=1750, loss=14.799 (0.008), acc=0.891, f1=0.803
epoch 142: train (21.41 sec): n=36250, loss=1.427 (0.008), acc=0.978, f1=0.973 | valid (1.26 sec): n=1750, loss=15.563 (0.008), acc=0.887, f1=0.793
epoch 143: train (21.03 sec): n=36250, loss=1.359 (0.008), acc=0.979, f1=0.975 | valid (1.27 sec): n=1750, loss=15.448 (0.008), acc=0.891, f1=0.790
epoch 144: train (21.04 sec): n=36250, loss=1.476 (0.008), acc=0.978, f1=0.973 | valid (1.26 sec): n=1750, loss=15.108 (0.008), acc=0.883, f1=0.786
epoch 145: train (21.07 sec): n=36250, loss=1.286 (0.008), acc=0.980, f1=0.976 | valid (1.26 sec): n=1750, loss=15.162 (0.008), acc=0.890, f1=0.800
epoch 146: train (21.04 sec): n=36250, loss=1.271 (0.008), acc=0.980, f1=0.976 | valid (1.26 sec): n=1750, loss=16.646 (0.008), acc=0.883, f1=0.786
epoch 147: train (21.48 sec): n=36250, loss=1.282 (0.008), acc=0.981, f1=0.977 | valid (1.26 sec): n=1750, loss=15.343 (0.008), acc=0.892, f1=0.808
epoch 148: train (21.47 sec): n=36250, loss=1.322 (0.008), acc=0.981, f1=0.977 | valid (1.29 sec): n=1750, loss=15.114 (0.008), acc=0.883, f1=0.802
epoch 149: train (21.26 sec): n=36250, loss=1.293 (0.008), acc=0.980, f1=0.976 | valid (1.31 sec): n=1750, loss=15.530 (0.008), acc=0.895, f1=0.818
 
[2018-01-25 23:52:17.450474] epoch 150:
train (21.179 sec): n=36250, loss=1.227 (0.008), acc=0.981, f1=0.976
[[ 7035    38    10     3     5]
 [   41  2303    62     1    13]
 [   10    47 15198   182    32]
 [    1     1   194  4502     1]
 [    3    10    26     0  6532]]
valid (1.263 sec): n=1750, loss=16.899 (0.008), acc=0.883, f1=0.792
[[309  11   4   1   4]
 [ 13  23  39   2  32]
 [  0   2 512  34   8]
 [  0   0  28 431   0]
 [  0   0  26   0 271]]
 
epoch 151: train (21.17 sec): n=36250, loss=1.297 (0.008), acc=0.980, f1=0.976 | valid (1.26 sec): n=1750, loss=16.635 (0.008), acc=0.895, f1=0.802
epoch 152: train (21.38 sec): n=36250, loss=1.252 (0.008), acc=0.981, f1=0.977 | valid (1.32 sec): n=1750, loss=15.823 (0.008), acc=0.892, f1=0.812
epoch 153: train (21.34 sec): n=36250, loss=1.272 (0.008), acc=0.980, f1=0.976 | valid (1.32 sec): n=1750, loss=15.937 (0.008), acc=0.885, f1=0.793
epoch 154: train (21.27 sec): n=36250, loss=1.300 (0.008), acc=0.980, f1=0.975 | valid (1.26 sec): n=1750, loss=16.226 (0.008), acc=0.892, f1=0.802
epoch 155: train (21.42 sec): n=36250, loss=1.227 (0.008), acc=0.982, f1=0.978 | valid (1.29 sec): n=1750, loss=16.009 (0.008), acc=0.886, f1=0.794
epoch 156: train (21.48 sec): n=36250, loss=1.259 (0.008), acc=0.981, f1=0.977 | valid (1.31 sec): n=1750, loss=15.457 (0.008), acc=0.886, f1=0.812
epoch 157: train (21.44 sec): n=36250, loss=1.261 (0.008), acc=0.982, f1=0.978 | valid (1.27 sec): n=1750, loss=17.260 (0.008), acc=0.883, f1=0.792
epoch 158: train (21.38 sec): n=36250, loss=1.284 (0.008), acc=0.981, f1=0.977 | valid (1.31 sec): n=1750, loss=15.959 (0.008), acc=0.889, f1=0.792
epoch 159: train (21.13 sec): n=36250, loss=1.210 (0.008), acc=0.982, f1=0.978 | valid (1.26 sec): n=1750, loss=17.101 (0.008), acc=0.883, f1=0.793
 
[2018-01-25 23:56:25.884813] epoch 160:
train (21.071 sec): n=36250, loss=1.255 (0.008), acc=0.981, f1=0.977
[[ 7042    32    12     1     4]
 [   43  2313    57     1     6]
 [    9    48 15180   201    31]
 [    1     0   188  4510     0]
 [    3    11    42     1  6514]]
valid (1.263 sec): n=1750, loss=15.331 (0.008), acc=0.896, f1=0.810
[[307  13   4   1   4]
 [ 13  28  29   2  37]
 [  1   4 514  25  12]
 [  0   0  22 436   1]
 [  0   0  14   0 283]]
 
epoch 161: train (21.07 sec): n=36250, loss=1.186 (0.008), acc=0.983, f1=0.979 | valid (1.26 sec): n=1750, loss=16.661 (0.008), acc=0.889, f1=0.798
epoch 162: train (21.57 sec): n=36250, loss=1.179 (0.008), acc=0.982, f1=0.978 | valid (1.30 sec): n=1750, loss=16.499 (0.008), acc=0.886, f1=0.810
epoch 163: train (21.50 sec): n=36250, loss=1.151 (0.008), acc=0.983, f1=0.980 | valid (1.32 sec): n=1750, loss=15.956 (0.008), acc=0.890, f1=0.801
epoch 164: train (21.05 sec): n=36250, loss=1.215 (0.008), acc=0.981, f1=0.977 | valid (1.26 sec): n=1750, loss=17.273 (0.008), acc=0.879, f1=0.794
epoch 165: train (21.26 sec): n=36250, loss=1.163 (0.008), acc=0.982, f1=0.979 | valid (1.33 sec): n=1750, loss=16.888 (0.008), acc=0.884, f1=0.794
epoch 166: train (21.20 sec): n=36250, loss=1.172 (0.008), acc=0.982, f1=0.978 | valid (1.27 sec): n=1750, loss=16.514 (0.008), acc=0.887, f1=0.801
epoch 167: train (21.28 sec): n=36250, loss=1.228 (0.008), acc=0.982, f1=0.977 | valid (1.27 sec): n=1750, loss=16.940 (0.008), acc=0.889, f1=0.804
epoch 168: train (21.43 sec): n=36250, loss=1.234 (0.008), acc=0.982, f1=0.978 | valid (1.30 sec): n=1750, loss=16.122 (0.008), acc=0.885, f1=0.811
epoch 169: train (21.35 sec): n=36250, loss=1.154 (0.008), acc=0.983, f1=0.979 | valid (1.27 sec): n=1750, loss=18.067 (0.008), acc=0.877, f1=0.789
 
[2018-01-26 00:00:30.299350] epoch 170:
train (21.136 sec): n=36250, loss=1.143 (0.008), acc=0.983, f1=0.980
[[ 7044    34     9     2     2]
 [   31  2329    43     0    17]
 [   12    30 15215   186    26]
 [    0     1   179  4519     0]
 [    4     5    27     0  6535]]
valid (1.264 sec): n=1750, loss=16.506 (0.008), acc=0.879, f1=0.805
[[303  16   5   1   4]
 [ 11  32  34   4  28]
 [  0   5 475  67   9]
 [  0   0  10 449   0]
 [  0   0  17   0 280]]
 
epoch 171: train (21.08 sec): n=36250, loss=1.155 (0.008), acc=0.983, f1=0.979 | valid (1.32 sec): n=1750, loss=16.848 (0.008), acc=0.890, f1=0.809
epoch 172: train (21.50 sec): n=36250, loss=1.095 (0.008), acc=0.984, f1=0.980 | valid (1.31 sec): n=1750, loss=16.486 (0.008), acc=0.881, f1=0.810
epoch 173: train (21.18 sec): n=36250, loss=1.108 (0.008), acc=0.984, f1=0.980 | valid (1.27 sec): n=1750, loss=19.172 (0.008), acc=0.875, f1=0.785
epoch 174: train (21.03 sec): n=36250, loss=1.142 (0.008), acc=0.982, f1=0.978 | valid (1.27 sec): n=1750, loss=16.931 (0.008), acc=0.883, f1=0.804
epoch 175: train (21.58 sec): n=36250, loss=1.150 (0.008), acc=0.983, f1=0.979 | valid (1.32 sec): n=1750, loss=17.973 (0.008), acc=0.881, f1=0.800
epoch 176: train (21.37 sec): n=36250, loss=1.107 (0.008), acc=0.984, f1=0.980 | valid (1.30 sec): n=1750, loss=16.299 (0.008), acc=0.878, f1=0.809
epoch 177: train (21.58 sec): n=36250, loss=1.099 (0.008), acc=0.984, f1=0.980 | valid (1.30 sec): n=1750, loss=17.230 (0.008), acc=0.878, f1=0.792
epoch 178: train (21.08 sec): n=36250, loss=1.089 (0.008), acc=0.984, f1=0.981 | valid (1.27 sec): n=1750, loss=15.172 (0.008), acc=0.890, f1=0.810
epoch 179: train (21.18 sec): n=36250, loss=1.141 (0.008), acc=0.983, f1=0.979 | valid (1.27 sec): n=1750, loss=18.498 (0.008), acc=0.879, f1=0.794
 
[2018-01-26 00:04:35.094796] epoch 180:
train (21.332 sec): n=36250, loss=1.162 (0.008), acc=0.983, f1=0.980
[[ 7042    33     7     3     6]
 [   29  2331    49     0    11]
 [    7    32 15214   187    29]
 [    1     2   176  4519     1]
 [    2     6    31     0  6532]]
valid (1.275 sec): n=1750, loss=17.921 (0.008), acc=0.881, f1=0.808
[[310  11   3   1   4]
 [ 12  33  27   2  35]
 [  0   6 479  57  14]
 [  0   0  19 440   0]
 [  0   0  18   0 279]]
 
epoch 181: train (21.35 sec): n=36250, loss=1.110 (0.008), acc=0.983, f1=0.979 | valid (1.32 sec): n=1750, loss=17.367 (0.008), acc=0.887, f1=0.805
epoch 182: train (21.52 sec): n=36250, loss=1.152 (0.008), acc=0.982, f1=0.978 | valid (1.33 sec): n=1750, loss=17.591 (0.008), acc=0.886, f1=0.807
epoch 183: train (21.23 sec): n=36250, loss=1.024 (0.008), acc=0.986, f1=0.982 | valid (1.30 sec): n=1750, loss=18.529 (0.008), acc=0.871, f1=0.794
epoch 184: train (21.20 sec): n=36250, loss=1.039 (0.008), acc=0.985, f1=0.981 | valid (1.27 sec): n=1750, loss=17.598 (0.008), acc=0.887, f1=0.801
epoch 185: train (21.26 sec): n=36250, loss=1.031 (0.008), acc=0.984, f1=0.981 | valid (1.33 sec): n=1750, loss=16.177 (0.008), acc=0.886, f1=0.809
epoch 186: train (21.57 sec): n=36250, loss=1.087 (0.008), acc=0.983, f1=0.980 | valid (1.35 sec): n=1750, loss=18.698 (0.008), acc=0.878, f1=0.787
epoch 187: train (21.37 sec): n=36250, loss=1.073 (0.008), acc=0.984, f1=0.980 | valid (1.27 sec): n=1750, loss=17.894 (0.008), acc=0.870, f1=0.782
epoch 188: train (21.44 sec): n=36250, loss=1.054 (0.008), acc=0.984, f1=0.981 | valid (1.28 sec): n=1750, loss=18.061 (0.008), acc=0.867, f1=0.793
epoch 189: train (21.51 sec): n=36250, loss=1.059 (0.008), acc=0.984, f1=0.981 | valid (1.31 sec): n=1750, loss=17.022 (0.008), acc=0.884, f1=0.791
 
[2018-01-26 00:08:41.015939] epoch 190:
train (21.530 sec): n=36250, loss=1.084 (0.008), acc=0.985, f1=0.982
[[ 7057    28     2     0     4]
 [   25  2347    33     1    14]
 [    9    35 15206   190    29]
 [    3     0   141  4554     1]
 [    2     7    27     0  6535]]
valid (1.305 sec): n=1750, loss=19.647 (0.008), acc=0.875, f1=0.781
[[313   5   4   1   6]
 [ 13  20  33   3  40]
 [  1   1 473  69  12]
 [  0   0  12 447   0]
 [  0   0  19   0 278]]
 
epoch 191: train (21.23 sec): n=36250, loss=1.007 (0.008), acc=0.985, f1=0.982 | valid (1.27 sec): n=1750, loss=17.755 (0.008), acc=0.887, f1=0.801
epoch 192: train (21.38 sec): n=36250, loss=0.953 (0.008), acc=0.986, f1=0.983 | valid (1.28 sec): n=1750, loss=17.921 (0.008), acc=0.876, f1=0.788
epoch 193: train (21.22 sec): n=36250, loss=1.005 (0.008), acc=0.985, f1=0.982 | valid (1.27 sec): n=1750, loss=19.062 (0.008), acc=0.874, f1=0.791
epoch 194: train (21.42 sec): n=36250, loss=0.986 (0.008), acc=0.985, f1=0.982 | valid (1.30 sec): n=1750, loss=20.108 (0.008), acc=0.874, f1=0.785
epoch 195: train (21.54 sec): n=36250, loss=1.077 (0.008), acc=0.984, f1=0.980 | valid (1.30 sec): n=1750, loss=18.069 (0.008), acc=0.877, f1=0.807
epoch 196: train (21.26 sec): n=36250, loss=1.004 (0.008), acc=0.985, f1=0.982 | valid (1.27 sec): n=1750, loss=18.690 (0.008), acc=0.871, f1=0.781
epoch 197: train (21.16 sec): n=36250, loss=1.025 (0.008), acc=0.985, f1=0.982 | valid (1.32 sec): n=1750, loss=19.217 (0.008), acc=0.878, f1=0.789
epoch 198: train (21.51 sec): n=36250, loss=0.923 (0.008), acc=0.986, f1=0.983 | valid (1.29 sec): n=1750, loss=17.071 (0.008), acc=0.879, f1=0.797
epoch 199: train (21.30 sec): n=36250, loss=0.969 (0.008), acc=0.986, f1=0.984 | valid (1.27 sec): n=1750, loss=19.310 (0.008), acc=0.877, f1=0.796
 
[2018-01-26 00:12:45.972275] epoch 200:
train (21.125 sec): n=36250, loss=1.045 (0.008), acc=0.984, f1=0.982
[[ 7053    24     6     4     4]
 [   24  2357    35     0     4]
 [    9    32 15237   169    22]
 [    1     0   187  4511     0]
 [    6     5    32     0  6528]]
valid (1.270 sec): n=1750, loss=18.100 (0.008), acc=0.873, f1=0.798
[[306  14   4   1   4]
 [ 11  31  26   2  39]
 [  1   5 463  69  18]
 [  0   0  15 444   0]
 [  0   0  14   0 283]]
 
Saved model checkpoint (3.169 sec)
Saved trained parameters (3.002 sec)
Finish fine-tuning
